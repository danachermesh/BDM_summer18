{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDM HW2_dcr346\n",
    "Student: Dana Chermesh Reshef, July 2018\n",
    "### task:\n",
    "Compute the number of restaurants per each cuisine using the provided **nyc_restaurant_inspections.csv** data set. The CSV file is available for download under the Data Sets page on NYU Classes. The cuisine type can be extracted from the _\"CUISINE DESCRIPTION\"_ column. Note that, a single restaurant may be inspected multiple times. You must use the _\"CAMIS\"_ column to keep only unique restaurants while computing the number of restaurants per cuisine.\n",
    "\n",
    "You MUST turn in a Spark notebook, AND a Spark script that works on the NYU Dumbo cluster. For your script, the input and out file path should be specified through the command line. Basically, I should be able to run your script as:\n",
    "\n",
    "`spark-submit YOUR_SCRIPT.py nyc_restaurant_inspections.csv output_folder`\n",
    "\n",
    "and it will produce an output on HDFS under output_folder.\n",
    "Using \"hadoop fs -getmerge\" or through the notebook, I should get the expected output similar to the below:\n",
    "\n",
    "```\n",
    "[('American', 6002),\n",
    " ('Chinese', 2399),\n",
    " ('Cafe', 1629),\n",
    " ('Other', 1296),\n",
    " ('Pizza', 1186),\n",
    " ('Italian', 1016),\n",
    " ('Mexican', 877),\n",
    " ('Japanese', 859),\n",
    " ('Latin (Cuban, Dominican, Puerto Rican, South & Central American)', 840),\n",
    " ('Bakery', 733),\n",
    " ('Caribbean', 671),\n",
    " ('Spanish', 644),\n",
    " ('Donuts', 537),\n",
    " ('Pizza/Italian', 483),\n",
    " ('Chicken', 456),\n",
    " ('Sandwiches', 406),\n",
    " ('Juice, Smoothies, Fruit Salads', 382),\n",
    " ('Hamburgers', 378),\n",
    " ('Asian', 371),\n",
    " ('Ice Cream, Gelato, Yogurt, Ices', 339),\n",
    " ('Indian', 332),\n",
    " ('Jewish/Kosher', 327),\n",
    " ('French', 319),\n",
    " ('Delicatessen', 294),\n",
    " ('Thai', 286)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://danas-mbp.fios-router.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYC_CUIS = 'nyc_restaurant_inspections.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'CAMIS'),\n",
       " (1, 'DBA'),\n",
       " (2, 'BORO'),\n",
       " (3, 'BUILDING'),\n",
       " (4, 'STREET'),\n",
       " (5, 'ZIPCODE'),\n",
       " (6, 'PHONE'),\n",
       " (7, 'CUISINE DESCRIPTION'),\n",
       " (8, 'INSPECTION DATE'),\n",
       " (9, 'ACTION'),\n",
       " (10, 'VIOLATION CODE'),\n",
       " (11, 'VIOLATION DESCRIPTION'),\n",
       " (12, 'CRITICAL FLAG'),\n",
       " (13, 'SCORE'),\n",
       " (14, 'GRADE'),\n",
       " (15, 'GRADE DATE'),\n",
       " (16, 'RECORD DATE'),\n",
       " (17, 'INSPECTION TYPE')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading NYC_CUIS to a RDD. \n",
    "# use_unicode can be changed accordingly to your data file to handle Unicode\n",
    "# If you cannot parse your data due to an 'utf8' or 'ascii' decoding issue, it might\n",
    "# be a good thing to try flipping the use_unicode parameter here.\n",
    "\n",
    "cuis = sc.textFile(NYC_CUIS, use_unicode=True).cache()\n",
    "\n",
    "# list the column index and column names to see\n",
    "# which column we need to use for our task. \n",
    "# In this case, I'm interested in the 'CAMIS' (#0) and the 'CUISINE DESCRIPTION' (#7).\n",
    "list(enumerate(cuis.first().split(',')))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Note that, our data input includes a header line that we don't want to\n",
    "# use in analysis. We can remove the header line from our RDD by doing\n",
    "# a 'filter' to remove all rows that matches the header like below. Though\n",
    "# this works, it means that we have to apply the filter function on *all*\n",
    "# row, which could be a lot of computation.\n",
    "\n",
    "noHeaderRDD = cuis.filter(lambda x: not x.startswith('CAMIS,DBA'))\n",
    "print (cuis.first())\n",
    "print (noHeaderRDD.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('50015075', 'Chicken'),\n",
       " ('40364529', 'Jewish/Kosher'),\n",
       " ('41580756', 'Caribbean'),\n",
       " ('50001255', 'Italian'),\n",
       " ('50016437', 'Korean')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using mapPartitionsWithIndex() to check if we're hitting the header\n",
    "# (aka the first partition). If so, we just skip the first row.\n",
    "\n",
    "def extractRest(partId, records):\n",
    "    if partId==0:\n",
    "        next(records)\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        (camis, cuisine) = (row[0], row[7])\n",
    "        yield (camis, cuisine)\n",
    "\n",
    "nycResturants = cuis.mapPartitionsWithIndex(extractRest)\n",
    "nycResturants.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American', 6002),\n",
       " ('Chinese', 2399),\n",
       " ('CafÃ©/Coffee/Tea', 1629),\n",
       " ('Other', 1296),\n",
       " ('Pizza', 1186),\n",
       " ('Italian', 1016),\n",
       " ('Mexican', 877),\n",
       " ('Japanese', 859),\n",
       " ('Latin (Cuban, Dominican, Puerto Rican, South & Central American)', 840),\n",
       " ('Bakery', 733),\n",
       " ('Caribbean', 671),\n",
       " ('Spanish', 644),\n",
       " ('Donuts', 537),\n",
       " ('Pizza/Italian', 483),\n",
       " ('Chicken', 456),\n",
       " ('Sandwiches', 406),\n",
       " ('Juice, Smoothies, Fruit Salads', 382),\n",
       " ('Hamburgers', 378),\n",
       " ('Asian', 371),\n",
       " ('Ice Cream, Gelato, Yogurt, Ices', 339),\n",
       " ('Indian', 332),\n",
       " ('Jewish/Kosher', 327),\n",
       " ('French', 319),\n",
       " ('Delicatessen', 294),\n",
       " ('Thai', 286)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nycCuisine = nycResturants \\\n",
    "            .map(lambda x: (x, 1)) \\\n",
    "            .reduceByKey(lambda x,y: 1) \\\n",
    "            .keys().map(lambda x: (x[1],1)) \\\n",
    "            .reduceByKey(lambda x,y: x+y) \\\n",
    "            .top(25, key=lambda x: x[1])\n",
    "\n",
    "nycCuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
